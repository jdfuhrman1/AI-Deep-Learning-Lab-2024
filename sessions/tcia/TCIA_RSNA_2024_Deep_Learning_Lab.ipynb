{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You can download and run this notebook locally, or you can run it for free in a cloud environment using Colab or Sagemaker Studio Lab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RSNA/AI-Deep-Learning-Lab-2024/blob/main/sessions/tcia/TCIA_RSNA_2024_Deep_Learning_Lab.ipynb)\n",
        "\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github.com/RSNA/AI-Deep-Learning-Lab-2024/blob/main/sessions/tcia/TCIA_RSNA_2024_Deep_Learning_Lab.ipynb)"
      ],
      "metadata": {
        "id": "DUmcjg7W2Pz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TCIA RSNA 2024 Deep Learning Lab\n",
        "\n",
        "Access to large, high-quality datasets is essential for researchers to understand disease and precision medicine pathways, especially in cancer. However, there are many challenges associated with publishing and utilizing radiological imaging data of human subjects. In this hands-on learning lab we'll teach you some solutions to these challenges, including how to properly de-identify and publish your DICOM data as well as how to access freely available datasets that have been published in online archives.\n",
        "\n",
        "This notebook was developed to demonstrate command-line and API-based options for accessing data from [The Cancer Imaging Archive](https://www.cancerimagingarchive.net/).  You can view the full course description, requirements and objects in the [RSNA 24 Meeting Program](https://reg.meeting.rsna.org/flow/rsna/rsna24/MeetingCentralRSNA24/page/session-catalog/session/1715624815092017Z13l).  "
      ],
      "metadata": {
        "id": "KmXfYFZtja2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brief intro to TCIA\n",
        "\n",
        "* [TCIA Overview Slides](https://github.com/RSNA/AI-Deep-Learning-Lab-2024/blob/main/sessions/tcia/2024-12-03_RSNA_Deep_Learning_Lab_Intro.pptx)\n",
        "\n",
        "Primary datasets are organized into [Collections](https://www.cancerimagingarchive.net/browse-collections/), which can include images and supporting data such as clinical, genomics, proteomics and image analyses (classifications, segmenatations, etc).  There are also secondary [Analysis Result](https://www.cancerimagingarchive.net/browse-analysis-results/) datasets, which are published by users who have downloaded the Collections and generated new data derived from them.  Generally these analysis datasets are additional image classifications and segmentations.\n",
        "\n",
        "In this learning lab we'll explore both types of datasets and a couple of the different systems we use to host them via the following use cases.\n"
      ],
      "metadata": {
        "id": "Sm7vVDkaWId6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Lab Use Cases\n",
        "\n",
        "1. You are a researcher interested in finding datasets that already have expert tumor segmentation labels to validate the performance of an AI tumor segmentation model you've developed.\n",
        "2. You are a researcher interested in doing a multi-modal study that includes clinical, genomic and proteomic classification labels that you can try to predict from the images.\n",
        "3. You are a researcher that wants to publish or share your analyses of existing TCIA image data with colleagues."
      ],
      "metadata": {
        "id": "4VzfkgDKBKh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "The following installs and imports **[tcia_utils](https://pypi.org/project/tcia-utils/)**, which contains a variety of useful functions for accessing TCIA via Python and Jupyter Notebooks.  It also installs [simpleDicomViewer](https://pypi.org/project/simpleDicomViewer/) to allow us to view some of the data we'll download directly in the notebook."
      ],
      "metadata": {
        "id": "BtHGbUj47d4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP4VRfgg-QXU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# install tcia utils\n",
        "!{sys.executable} -m pip install --upgrade -q tcia_utils\n",
        "\n",
        "# install simpleDicomViewer and forked pydicom-seg dependency\n",
        "!{sys.executable} -m pip install --upgrade -q git+https://github.com/kirbyju/pydicom-seg.git@master\n",
        "!{sys.executable} -m pip install --upgrade -q simpleDicomViewer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll import modules to help us work with a few different TCIA APIs and change the logging settings if you're on Colab so you can see more of the INFO statements that tell you what's going on as we run our commands."
      ],
      "metadata": {
        "id": "wSFYJdY3-DeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3zEqnxi9rk2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import io\n",
        "from tcia_utils import wordpress\n",
        "from tcia_utils import nbia\n",
        "from simpleDicomViewer import dicomViewer\n",
        "\n",
        "# set logging level to INFO\n",
        "import logging\n",
        "\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "# Set handler with level = info\n",
        "logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',\n",
        "                    level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case: Find datasets with tumor labels to test AI segmentation models\n",
        "\n",
        "Many collections on TCIA contain tumor segmentations which can be used for training and testing artificial intelligence models.  In this section of the course we'll review some tips and tricks for finding them using our Wordpress API (aka Collection Manager).  It contains metadata about the datasets we host including descriptive summaries, stats about the files available for download, citation requirements, related publications and versioning info. Full documentation about this API can be found at https://www.cancerimagingarchive.net/collection-manager-rest-api/, but we'll rely on the **wordpress** module in **tcia_utils** to simplify some common tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "2gU9e6zA7SqL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPpOFV3jiDT"
      },
      "source": [
        "## Exploring collection metadata\n",
        "In order to get metadata about collections with tcia_utils we'll use the **wordpress.getCollections()** function and save the results to a dataframe that we'll be able to use to start looking for relevant datasets with segmentations.\n",
        "\n",
        "**Note:** You can mouse over function names in Colab to view their docstrings. These provide helpful explanations about what the functions do and the available parameters you can use with them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm_mlAmuO6XS"
      },
      "outputs": [],
      "source": [
        "# select fields to retrieve\n",
        "fields = [\"id\", \"slug\", \"collection_page_accessibility\", \"link\", \"cancer_types\",\n",
        "          \"collection_doi\", \"cancer_locations\", \"collection_status\", \"species\",\n",
        "          \"versions\", \"citations\", \"collection_title\", \"version_number\",\n",
        "          \"date_updated\", \"subjects\", \"collection_short_title\", \"data_types\",\n",
        "          \"supporting_data\", \"program\", \"collection_summary\",\n",
        "          \"collection_downloads\", \"related_analysis_results\"]\n",
        "\n",
        "# request metadata\n",
        "collections = wordpress.getCollections(format = \"df\", fields = fields, file_name = \"tciaCollections.csv\", removeHtml = \"yes\")\n",
        "\n",
        "collections"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering for datasets with segmentation labels\n",
        "As you can see, there's quite a bit of information in this dataframe.  In order to find the ones with segmentations, the most important columns to check are **data_types**\tand **supporting_data**.\n",
        "\n",
        "Let's look at data_types first.  DICOM provides support for segmentations using SEG and RTSTRUCT modalities.  Many popular open-source tools export these labels in other formats.  Popular formats include NIFTI, NRRD, and MHA.  TCIA contains segmentation data in pretty much all of these formats.  When querying our datasets, you can filter for **SEG and RTSTRUCT** to catch the DICOM segmentations.  If a Collection contains this type of data in other formats we simply list them as **Segmentations**.\n",
        "\n",
        "Seasoned data scientists can filter for these values in our Collections dataframe using regular Pandas commands, but to help make the course more beginner friendly we'll use the **searchDf()** helper function from tcia_utils to make it even easier.  We'll include our search terms as the first parameter and the dataframe we want to filter as the second one."
      ],
      "metadata": {
        "id": "ht86eUPz3PTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that 'seg' catches both SEG (dicom) and (Segmentation) values here\n",
        "segs = wordpress.searchDf(['seg','rtstruct'], column_name = \"data_types\", dataframe = collections)\n",
        "\n",
        "segs"
      ],
      "metadata": {
        "id": "8fanWBU25GnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take advantage of the AI-driven coding features of Colab to auto-generate some code to plot this data in a bar chart."
      ],
      "metadata": {
        "id": "e7hNnCjC6QdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a bar chart with plotly showing how many collections have SEG vs RTSTRUCT vs Segmentation in the data_type column.  Note that the values in this column are lists.\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Count occurrences of 'SEG', 'RTSTRUCT', and 'Segmentation' in the 'data_type' column\n",
        "seg_count = 0\n",
        "rtstruct_count = 0\n",
        "segmentation_count = 0\n",
        "\n",
        "for index, row in segs.iterrows():\n",
        "    data_types = row['data_types']\n",
        "    if isinstance(data_types, list):  # Check if data_types is a list\n",
        "        if 'SEG' in data_types:\n",
        "            seg_count += 1\n",
        "        if 'RTSTRUCT' in data_types:\n",
        "            rtstruct_count += 1\n",
        "        if 'Segmentation' in data_types:\n",
        "            segmentation_count += 1\n",
        "\n",
        "# Create a DataFrame for the bar chart\n",
        "import pandas as pd\n",
        "data = {'Data Type': ['SEG', 'RTSTRUCT', 'Segmentation'],\n",
        "        'Count': [seg_count, rtstruct_count, segmentation_count]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the bar chart using Plotly Express\n",
        "fig = px.bar(df, x='Data Type', y='Count',\n",
        "             title='Number of Collections with Segmentation Data Types',\n",
        "             labels={'Count': 'Number of Collections'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wCohWER55v1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say that you were specifically interested in working with a lung cancer tumor segmentation model.  Try using the Colab AI assistant to help you filter the **segs** dataframe to down to only the lung datasets.\n",
        "\n",
        "**Note:** You can click \"generate with AI\" or you can type out what you need help with using code comments and it will auto-suggest solutions when you go to the next line."
      ],
      "metadata": {
        "id": "EAWn81H78LG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: filter my \"segs\" dataframe for rows that contain \"lung\"\n",
        "\n",
        "# Filter the 'segs' DataFrame for rows containing \"lung\" in the 'cancer_types' column.\n",
        "lung_segs = segs[segs['cancer_types'].astype(str).str.contains(\"lung\", case=False, na=False)]\n",
        "\n",
        "lung_segs"
      ],
      "metadata": {
        "id": "06X7_vmR8rXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now review the datasets you've identified to decide which ones you'd like to include in your project.  In the interest of time, let's say that after reviewing them you decided you wanted to work with [RIDER Lung CT](https://doi.org/10.7937/k9/tcia.2015.u1x8a5nr).  Go ahead and take a quick look at this page so we can see how it looks compared to the API output we'll generate in a minute.\n",
        "\n",
        "In order to download the data from the links that you see in the \"Data Access\" table of the RIDER Lung CT web page, we need to first use the **getDownloads()** function to look up the **id** values in the **collection_downloads** column."
      ],
      "metadata": {
        "id": "DcC8S_4b9W1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the ids in the 'collection_downloads' column of my 'lung' dataframe to a list where collection short title = \"RIDER Lung CT\"\n",
        "\n",
        "# Assuming 'collections' dataframe is already loaded as in the provided code.\n",
        "\n",
        "rider_lung_ct_ids = []\n",
        "\n",
        "# Iterate through the rows of the dataframe\n",
        "for index, row in collections.iterrows():\n",
        "    if row['collection_short_title'] == \"RIDER Lung CT\":\n",
        "        # Extract and append the ids from the 'collection_downloads' column.\n",
        "        # Handle cases where 'collection_downloads' might be a string, list, or missing.\n",
        "        if isinstance(row['collection_downloads'], list):\n",
        "            rider_lung_ct_ids.extend(row['collection_downloads'])\n",
        "        elif isinstance(row['collection_downloads'], str):\n",
        "          rider_lung_ct_ids.append(row['collection_downloads'])\n",
        "        # You can add an 'else' block to handle missing values if needed,\n",
        "        # e.g. else: print(f\"Missing collection_downloads for {row['collection_short_title']}\")\n",
        "        break # Assuming there's only one row with that title\n",
        "\n",
        "rider_lung_ct_ids"
      ],
      "metadata": {
        "id": "yPFR_hlC_Ha_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we have 2 ids, which correspond to the 2 download rows you saw on the web page.  Let's feed these ids to the getDownloads() function now.  We'll also provide a subset of the more interesting fields to focus on rather than returning them all."
      ],
      "metadata": {
        "id": "NGSbeUe8AKkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [\"id\", \"date_updated\", \"download_title\", \"data_license\", \"download_access\",\n",
        "          \"data_type\", \"file_type\", \"download_size\", \"download_size_unit\",\n",
        "          \"subjects\", \"study_count\", \"series_count\", \"image_count\",\n",
        "           \"download_type\", \"download_url\", \"download_file\", \"search_url\"]\n",
        "\n",
        "downloads = wordpress.getDownloads(ids = rider_lung_ct_ids, fields=fields, format = \"df\")\n",
        "downloads"
      ],
      "metadata": {
        "id": "7Zbkm9lI_m9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the results, we can see that the first row contains the DICOM data with both the CT images and segmentations.  Let's grab that download_url and use it to save the file."
      ],
      "metadata": {
        "id": "MWeZrGYNDiag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe downloads: download the file from the URL in the download_url field where file_type contains \"DICOM\". Note that file_type is a list.\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Assuming 'downloads' is your pandas DataFrame\n",
        "# Find rows where 'file_type' contains \"DICOM\"\n",
        "dicom_downloads = downloads[downloads['file_type'].astype(str).str.contains(\"DICOM\")]\n",
        "\n",
        "# Iterate through the filtered DataFrame and download the files\n",
        "for index, row in dicom_downloads.iterrows():\n",
        "    url = row['download_url']\n",
        "    # Get the filename from the URL\n",
        "    filename = url.split('/')[-1]\n",
        "    print(f\"Downloading file from: {url}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Downloaded {filename} successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {filename}: {e}\")"
      ],
      "metadata": {
        "id": "bF_hZlPjC_f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading with the Linux Command Line NBIA Data Retriever\n",
        "\n",
        "TCIA uses software called NBIA to manage its DICOM data.  One way to download TCIA data is to install the NBIA Data Retriever and use it to open a **.TCIA** manifest that contains the list of files to download.\n",
        "\n",
        "This tool provides a number of useful features such as auto-retry if there are any problems, saving data in an organized hierarchy on your hard drive (Collection > Patient > Study > Series > Images), and providing a CSV file containing key DICOM metadata about the images you've downloaded.  "
      ],
      "metadata": {
        "id": "eRvQa63-kJIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the NBIA Data Retriever\n",
        "There are versions of this tool for Windows, Mac and Linux.  If you're working from a system with a GUI you can follow the [instructions](https://wiki.cancerimagingarchive.net/display/NBIA/Downloading+TCIA+Images) to install Data Retriever on your computer.\n",
        "\n",
        "There is also a [command-line version of the NBIA Data Retriever](https://wiki.cancerimagingarchive.net/x/2QKPBQ) which can be installed via the steps below if you're running this notebook in a **Linux** environment.  "
      ],
      "metadata": {
        "id": "RtLE_18NoaJ8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B714bOkDk8kd"
      },
      "source": [
        "# Install NBIA Data Retriever CLI software for downloading images later in this notebook.\n",
        "\n",
        "!mkdir /usr/share/desktop-directories/\n",
        "!wget -P /content/NBIA-Data-Retriever https://github.com/CBIIT/NBIA-TCIA/releases/download/DR-4_4_3-TCIA-20240916-1/nbia-data-retriever_4.4.3-1_amd64.deb\n",
        "!dpkg -i /content/NBIA-Data-Retriever/nbia-data-retriever_4.4.3-1_amd64.deb\n",
        "\n",
        "# NOTE: If you're working on a Linux OS that uses RPM packages, you can change the lines above to use\n",
        "#       https://github.com/CBIIT/NBIA-TCIA/releases/download/DR-4_4_3-TCIA-20240916-1/nbia-data-retriever-4.4.3-1.x86_64.rpm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Click on the icon in the left sidebar that looks like a file folder to view the files we've downloaded thus far. You can inspect the manifest file in a text editor by double clicking it. You'll see some configuration information at the top, followed by a list of Series Instance UIDs that are part of the dataset.  \n",
        "\n",
        "Don't worry if this next cell doesn't make much sense.  Typically you wouldn't need to do this, but for the purposes of this demo I'm  editing the file to only include the UIDs for a single CT + Segmentation from this Collection so that we're not waiting a long time for the full dataset to download.\n",
        "\n"
      ],
      "metadata": {
        "id": "cPlvJcdKFhRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/RIDER-Lung-CT_v3_20240625.tcia /content/RIDER-sample.tcia\n",
        "\n",
        "# Open the original file for reading and the new file for writing\n",
        "with open('/content/RIDER-Lung-CT_v3_20240625.tcia', 'r') as infile, open('/content/RIDER-sample.tcia', 'w') as outfile:\n",
        "    # Read the first six lines and write them to the new file\n",
        "    for i in range(6):\n",
        "        line = infile.readline()\n",
        "        outfile.write(line)\n",
        "    outfile.write(\"1.2.276.0.7230010.3.1.3.8323329.3151.1554820054.833742\\n\")\n",
        "    outfile.write(\"1.3.6.1.4.1.9328.50.1.244501235124778437799277943012383090930\\n\")\n",
        "    outfile.write(\"1.2.246.352.71.2.494841863751.4253265.20190214220030\")"
      ],
      "metadata": {
        "id": "OAFZvotWPKvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlPLgxkBZPMS"
      },
      "source": [
        "### Open the Manifest File with the NBIA Data Retriever\n",
        "Next, let's open the sample manifest file with the NBIA Data Retriever to download the actual DICOM data.  To do this, we'll call the command to launch Data Retriever, specify the **--cli** flag to indicate we want to run this via command line (not with a GUI).  We also need to specify the path to the manifest file we want to open and then use **-d** to specify the path where we want to save the data.\n",
        "\n",
        "**<font color='red'>We are using the --agree-to-license flag to bypass the need to interactively agree to the [Data Usage Policy](https://www.cancerimagingarchive.net/data-usage-policies-and-restrictions/)</font>**.  Please be sure you always check the licensing and attribution requirements before utilizing any TCIA data in your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4lklpk4Xwpc"
      },
      "outputs": [],
      "source": [
        "# download the data using NBIA Data Retriever\n",
        "\n",
        "!/opt/nbia-data-retriever/bin/nbia-data-retriever --cli '/content/RIDER-sample.tcia' -d /content/ --agree-to-license"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the simpleDicomViewer we imported at the beginning of the notebook to take a quick look at these scans in the notebook.  You can use the slider to scroll through the image stack."
      ],
      "metadata": {
        "id": "m9Tk1opwJVIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you didn't change the default download options for downloadSeries\n",
        "imgPath = \"/content/RIDER-sample/RIDER Lung CT/RIDER-1532432635/04-12-2007-05084/109.000000-90930\"\n",
        "\n",
        "# The annotation path has to be a file name (not directory name).  Since there is generally\n",
        "# only one file in a segmentation series we can assume it will always be called 1-1.dcm\n",
        "segPath = \"/content/RIDER-sample/RIDER Lung CT/RIDER-1532432635/04-12-2007-05084/110.000000-TEST-20030/1-1.dcm\"\n",
        "\n",
        "# Display the viewer\n",
        "dicomViewer.viewSeriesAnnotation(imgPath, segPath)"
      ],
      "metadata": {
        "id": "e4vXNGzsJlW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgESwVXSawv_"
      },
      "source": [
        "### NBIA Data Retriever Conclusion\n",
        "You should now find that the data have been saved to your machine in a well-organized hierarchy with some useful metadata in the accompanying CSV file and a license file detailing how it can be used.  Take a look at the data before moving on.\n",
        "\n",
        "A few other notes:\n",
        "* The CLI Data Retriever supports both \"Descriptive\" and \"Classic\" organization of the data.  Descriptive naming uses information from the DICOM Study/Series Description and Dates to make them easier for humans to interpret.  Classic names everything by machine-readable unique identifiers.  If you prefer machine-readable directory names simply add the **-cd** parameter to your download command.\n",
        "* In some cases, you must specifically request access to [Collections](https://www.cancerimagingarchive.net/browse-collections/) before you can download them.  Information about how to do this can be found on the homepage for the Collection(s) you're interested in, but will always require that you first [create a TCIA user account](https://wiki.cancerimagingarchive.net/x/xgHDAg).  Once you've created an account and obtained permission to the restricted data you want to download, you can use your login/password to create the **credentials.txt** file that NBIA Data Retriever uses to verify your permissions.  The path to the credential file is specified using the **-l** parameter.\n",
        "\n",
        "You can find examples for these use cases at [TCIA_Linux_Data_Retriever_App.ipynb](https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_Linux_Data_Retriever_App.ipynb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case: Predict clinical, genomic and proteomic classification from images\n",
        "In this use case we'll look for datasets that have clinical, genomic and proteomic supporting data and then grab their related images.  \n",
        "\n",
        "**Note:** It's outside the scope of this notebook to do a deep dive on how to obtain the genomic and proteomic data, but you can find lots of additional information about the NCI programs that are generating this type of data and how to access it at https://www.cancerimagingarchive.net/imaging-omics/.\n",
        "\n",
        "To get started, let's filter the collections dataframe again that we created earlier.  This time we'll look for 'omics' in the **supporting_data** column."
      ],
      "metadata": {
        "id": "zKgz-mapNo0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "omics = wordpress.searchDf('omics', column_name = \"supporting_data\", dataframe = collections)\n",
        "\n",
        "omics"
      ],
      "metadata": {
        "id": "tdtmZXZbV04B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over 40 datasets!  Let's say that I'm particularly interested in pancreatic data though."
      ],
      "metadata": {
        "id": "-U3NIGs4WBd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pancreas_omics = wordpress.searchDf('pancreas', dataframe = omics)\n",
        "\n",
        "pancreas_omics"
      ],
      "metadata": {
        "id": "82Le5BXOWJ_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, we're down to one called **CPTAC-PDA** now, but it looks like a good candidate since it also has clinical data listed in the supporting_data column.  \n",
        "\n",
        "Let's navigate to the URL in the link column.  "
      ],
      "metadata": {
        "id": "rgvAq5knWTk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the full value of the URL in the link column of my pancreas_omics dataframe\n",
        "\n",
        "# Assuming 'pancreas_omics' DataFrame is already loaded as in the provided code.\n",
        "\n",
        "for index, row in pancreas_omics.iterrows():\n",
        "    print(row['link'])"
      ],
      "metadata": {
        "id": "BZuCaSbfWmkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, in addition to the images, there are Analysis Result datasets which have been published containing image segmentations.  This looks like a really great dataset to explore in more detail!"
      ],
      "metadata": {
        "id": "JzNwphxWX--6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVOOJWDckJIa"
      },
      "source": [
        "## Accessing DICOM REST APIs\n",
        "Instead of just downloading the full dataset with NBIA Data Retriever like we did earlier, this time we'll use the [NBIA REST APIs](https://wiki.cancerimagingarchive.net/x/ZoATBg) to query metadata and download DICOM data.  These can be particularly helpful if you want to build a more customized cohort, or if you can't or don't want to install software like the Data Retriever in your computational environment.\n",
        "\n",
        "In this notebook we'll rely heavily on [tcia_utils](https://pypi.org/project/tcia-utils/) again to simplify accessing the APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6D_3Dn7kJIa"
      },
      "source": [
        "## Exploring the data with REST API queries\n",
        "\n",
        "Let's start by looking at what body parts and modalities are contained in the CPTAC-PDA collection.  By default, most functions from **tcia_utils** return results in JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLDN4BAhbhvZ"
      },
      "outputs": [],
      "source": [
        "# count patients for each modality\n",
        "data = nbia.getModalityCounts(collection = \"CPTAC-PDA\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFrw8FAlkY8x"
      },
      "source": [
        "However, you can also use **format = \"df\"** to return the results as a dataframe.  Let's try that for looking at the patient counts by Body Part Examined values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FZqff2fkJIa"
      },
      "outputs": [],
      "source": [
        "# Count patients for each body part examined,\n",
        "# return results as dataframe\n",
        "df = nbia.getBodyPartCounts(collection = \"CPTAC-PDA\", format = \"df\")\n",
        "\n",
        "# rename headers and sort by PatientCount\n",
        "df.rename(columns = {'criteria':'BodyPartExamined', 'count':'PatientCount'}, inplace = True)\n",
        "df.PatientCount = df.PatientCount.astype(int)\n",
        "display(df.sort_values(by='PatientCount', ascending=False, ignore_index = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJQQ4-_ZkJIa"
      },
      "source": [
        "Now let's run **nbia.getPatient()** and **nbia.getStudy()** to see what we can learn about the patient cohort from the DICOM metadata.  The patient information can include things like age, gender, and ethnicity. The study information might include additional information recorded on the date the patient was scanned such as the patient's age or how many days it has been since they were diagnosed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUBlXp7P_JI8"
      },
      "outputs": [],
      "source": [
        "df = nbia.getPatient(collection = \"CPTAC-PDA\", format = \"df\")\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IkG3w4Xb6W7"
      },
      "source": [
        "Let's use **format = \"csv\"** this time to save a CSV file in addition to returning a dataframe.  Verify that **getPatientStudy.csv** has been saved to your file system before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kn8nhMSB5u1"
      },
      "outputs": [],
      "source": [
        "# obtain study/visit details (e.g. anonymized study date, age at the time of visit)\n",
        "df = nbia.getStudy(collection = \"CPTAC-PDA\", format = \"csv\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BahXeSfFkJIb"
      },
      "source": [
        "We can also create a report with **nbia.getSeries()** that gives useful metadata about each scan in the dataset (e.g. series description, modality, scanner manufacturer & software version, number of images).  Here's a full list of the return values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQVbwxCEkJIb"
      },
      "outputs": [],
      "source": [
        "# obtain scan/series metadata and save to variable for use in next example\n",
        "series = nbia.getSeries(collection = \"CPTAC-PDA\", format = \"df\")\n",
        "\n",
        "# list all column headers in the series dataframe\n",
        "list(series.columns)\n",
        "\n",
        "# uncomment the next line if you'd like to see the actual data\n",
        "#display(series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8p4rjHCkJIb"
      },
      "source": [
        "Finally, we can use the results from the getSeries() query to generate some summary statistics about the data in the collection.  Note that there are separate rows summarizing the contents of the original collection and the contents any related Analysis Result datasets that have DICOM data.  \n",
        "\n",
        "The other Analysis Result datasets we saw on the CPTAC-PDA webpage do not appear because the data they generated were other file formats that were not submitted to the NBIA DICOM system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYS-sdd7kJIb"
      },
      "outputs": [],
      "source": [
        "# Calculate summary statistics for a given collection\n",
        "nbia.reportDoiSummary(series, input_type = \"df\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWUOGHyLkJIb"
      },
      "source": [
        "## Downloading data with the REST API\n",
        "There are a wide variety of ways to use **downloadSeries()** to download data from TCIA.  You can learn more about this in https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_REST_API_Downloads.ipynb, but we'll cover a few basic use cases in this notebook.\n",
        "\n",
        "First we'll demonstrate downloading a segmentation and the corresponding image series for a single subject.  To do this we'll pull a random segmentation using the **series** dataframe we created earlier with **getSeries()**.  All annotation data in the CPTAC-PDA collection is in RTSTRUCT format, so we'll filter for this in the Modality column and then use SeriesDescription to make sure we're pulling a 3d segmentation and not a seed point annotation as they're too small to visualize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFEOLIYRs33G"
      },
      "outputs": [],
      "source": [
        "random_row = series.loc[(series['Modality'] == 'RTSTRUCT') &\n",
        "                        (~series['SeriesDescription'].fillna('').str.lower().str.contains('seed'))].sample(n=1)\n",
        "segSeries = random_row['SeriesInstanceUID'].iloc[0]\n",
        "\n",
        "print(segSeries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NVZAb3qu_X4"
      },
      "source": [
        "To determine the Reference Series UID of the image data that goes with this segmentation you can use **nbia.getSegRefSeries()**.\n",
        "\n",
        "**Note:** This should work 100% of the time with RTSTRUCT data, but there are some older SEG datasets that were submitted to us without this DICOM element populated so you may encounter issues using this function with those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jogkmh9kvMoW"
      },
      "outputs": [],
      "source": [
        "refSeries = nbia.getSegRefSeries(segSeries)\n",
        "\n",
        "print(refSeries)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wanted to inspect the DICOM tags for these series before downloading them you can use the **nbia.reportDicomTags()** function.  \n",
        "\n",
        "**Note:** This function looks up each series UID with a separate API call, so if you run this with a really large list of UIDs it could take a very long time."
      ],
      "metadata": {
        "id": "6RRRGcaXZ482"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbia.reportDicomTags([refSeries, segSeries])"
      ],
      "metadata": {
        "id": "rKFZLQjZaEFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkMkyHoYwC2F"
      },
      "source": [
        "Next let's download these two series by passing their UIDs as a list.  Note that this is not the default way downloadSeries() expects to receive input about what to download.  This is why we're specifying input_type = \"list\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P-s8sZBwIIz"
      },
      "outputs": [],
      "source": [
        "nbia.downloadSeries([refSeries, segSeries], input_type= \"list\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HU0fGOwvxxO"
      },
      "source": [
        "Now we can look at the images and segmentation together with **viewSeriesAnnotation()** from [simpleDicomViewer](https://pypi.org/project/simpleDicomViewer/).  Note that this function is only meant to be a  quick and dirty way to preview the data.  There are more comprehensive solutions such as [3D Slicer](https://slicer.org/) or [itkWidgets](https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_RTStruct_SEG_Visualization_with_itkWidgets.ipynb) if you want analyze the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZb33aCNv24K"
      },
      "outputs": [],
      "source": [
        "# Assuming you didn't change the default download options for downloadSeries\n",
        "imgPath = \"tciaDownload/\" + refSeries\n",
        "\n",
        "# The annotation path has to be a file name (not directory name).  Since there is generally\n",
        "# only one file in a segmentation series we can assume it will always be called 1-1.dcm\n",
        "segPath = \"tciaDownload/\" + segSeries + \"/1-1.dcm\"\n",
        "\n",
        "# Display the viewer\n",
        "dicomViewer.viewSeriesAnnotation(imgPath, segPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say that after spot checking a few cases you decide you'd like to download the full dataset.  To achieve this, we can pass the full `series` dataframe we created earlier to `downloadSeries()` as shown here.  We'll need to include the `input_type` parameter again because the function expects JSON by default and we're using a dataframe here."
      ],
      "metadata": {
        "id": "9zOAj7egn8Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: the 'number' parameter lets you specify how many series to download\n",
        "# This is useful for demos or if you just want a small sample of data for testing.\n",
        "\n",
        "nbia.downloadSeries(series, number = 2, input_type = 'df')"
      ],
      "metadata": {
        "id": "6IkodSHooTSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing Genomics, Proteomics and Clinical data\n",
        "NCI has funded several large projects generating vast amounts of imaging, proteomic, genomic and clinical data.  While TCIA hosts much of the imaging data for these projects, the 'omic and clinical data are hosted in the [Proteomic Data Commons (PDC)](https://pdc.cancer.gov/) and [Genomic Data Commons (GDC)](https://gdc.cancer.gov/).  \n",
        "\n",
        "In the interest of time, we will only touch briefly on how to access the clinical data for CPTAC-PDA.  \n",
        "* If you are interested in learning more about how to access imaging and clinical data from these datasets please check out the notebooks for the [Clinical Proteomic Tumor Analysis Consortium (CPTAC)](https://github.com/kirbyju/TCIA_Notebooks/blob/main/CPTAC/CPTAC.ipynb) and [The Cancer Genome Atlas (TCGA)](https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCGA/TCGA_Clinical.ipynb).\n",
        "* If you have questions about accessing the genomic or proteomic data please contact [GDC support](mailto:support@nci-gdc.datacommons.io) or [PDC support](mailto:PDCHelpDesk@mail.nih.gov)."
      ],
      "metadata": {
        "id": "6N1kHJFnb5VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cases_endpt = 'https://api.gdc.cancer.gov/cases'\n",
        "\n",
        "filters = {\n",
        "    \"op\": \"in\",\n",
        "    \"content\":{\n",
        "        \"field\": \"project.project_id\",\n",
        "        \"value\": [\"CPTAC-3\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "fields = [\n",
        "    \"submitter_id\",\n",
        "    ]\n",
        "\n",
        "fields = ','.join(fields)\n",
        "\n",
        "expand = [ ## For the allowable values for this list, look under \"mapping\" at https://api.gdc.cancer.gov/cases/_mapping\n",
        "    \"demographic\",\n",
        "    \"diagnoses\",\n",
        "    \"diagnoses.treatments\",\n",
        "    \"exposures\",\n",
        "    \"family_histories\"\n",
        "    ]\n",
        "\n",
        "expand = ','.join(expand)\n",
        "\n",
        "params = {\n",
        "    \"filters\": json.dumps(filters),\n",
        "    \"expand\": expand,\n",
        "    \"fields\": fields,\n",
        "    \"format\": \"TSV\", ## This can be \"JSON\" too\n",
        "    \"size\": \"2000\", ## If you are including several projects, I would recommend playing with this and the \"from\" number.\n",
        "    \"from\":\"0\"\n",
        "    }\n",
        "\n",
        "response = requests.get(cases_endpt, params = params)\n",
        "\n",
        "output = response.content.decode('UTF-8')\n",
        "clinicalDf = pd.read_csv(io.StringIO(output), sep='\\t')\n",
        "\n",
        "clinicalDf"
      ],
      "metadata": {
        "id": "mrQIHMOWet11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PUShHIvp_ME"
      },
      "source": [
        "Now let's merge the clinical data with our imaging data so that we're only looking at subjects where we have both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-fdbnVTyhRp"
      },
      "outputs": [],
      "source": [
        "# create new dataframe from 'series' with unique IDs of patients with imaging\n",
        "uniquePatients = pd.DataFrame(series['PatientID'].unique(), columns=['PatientID'])\n",
        "\n",
        "# Rename the patient id column in clinicalDf to match\n",
        "clinicalDf = clinicalDf.rename(columns={'submitter_id': 'PatientID'})\n",
        "\n",
        "# Merge the dataframes\n",
        "mergedClinical = uniquePatients.merge(clinicalDf, how='left', on='PatientID')\n",
        "\n",
        "mergedClinical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll stop there for now, but from here you could review the clinical data in more detail and start looking for possible fields that you want to try to predict from the imaging data."
      ],
      "metadata": {
        "id": "SPNid4huftaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case: Publishing or sharing your analyses of TCIA images\n",
        "After accessing TCIA data you may find that you'd like to publish your results in connection with a manuscript, or maybe you just want to share specific data with others to demonstrate your model's performance.  Here, we will demonstrate how the API can help you achieve this, as well as discuss general considerations and best practices.\n",
        "\n",
        "Let's say that you're a researcher interested in developing or refining an all-purpose foundational tumor segmentation model for CT images.  You might begin by using **getSimpleSearchWithModalityAndBodyPartPaged()**.  Take a minute to look at the docstring for this function.  It's extremely powerful and versatile!\n",
        "\n",
        "We'll run this twice to create a starting point for the data we may want to use for creating our model.  The first query is returning the CT/SEG series from subjects that have both CT AND SEG, and the second is returning RTSTRUCT/CT series from subjects that have both CT AND RTSTRUCT segmentations."
      ],
      "metadata": {
        "id": "0VC-WkRlf6Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct_seg = nbia.getSimpleSearchWithModalityAndBodyPartPaged(modalities=['CT', 'SEG'], modalityAnded=True, format = 'uids')\n",
        "ct_rtstruct = nbia.getSimpleSearchWithModalityAndBodyPartPaged(modalities=['CT', 'RTSTRUCT'], modalityAnded=True, format = 'uids')"
      ],
      "metadata": {
        "id": "8L87hzqZqBF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in the following cell that this results in approximately 30,000 series to review.  \n"
      ],
      "metadata": {
        "id": "zVBcNu6ttEr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ct_seg))\n",
        "print(len(ct_rtstruct))"
      ],
      "metadata": {
        "id": "jJX7k324s7yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we can use **getSeriesList()** to retrieve metadata for these series and save that as a CSV for both datasets. Take a minute to review what sort of metadata are in the spreadsheets by double clicking one of the files in the left sidebar to open it."
      ],
      "metadata": {
        "id": "L4u8vOojtYpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbia.getSeriesList(ct_seg, format = 'csv')\n",
        "\n",
        "nbia.getSeriesList(ct_rtstruct, format = 'csv')"
      ],
      "metadata": {
        "id": "LQUk5RM0rVeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the real fun begins.  You can do some data wrangling with these spreadsheets to rule out some series you obviously don't want.  For example, you might want to eliminate scans with certain Series Descriptions (e.g. \"Scout\") or that have less than a certain number of images in them.  \n",
        "\n",
        "Let's pretend that after doing this you've created a new file, **series.csv** where you've retained only the series you think are worth downloading for further review.  Please use the file manager in the left sidebar to right click and rename one of the **series_report_datetime.csv** spreadsheets you downloaded in our previous steps to **series.csv**.  \n",
        "\n",
        "Next we'll demonstrate how to download those series using the CSV file by isolating the Series Instance UIDs and passing them to **downloadSeries()** with **input_type = 'list'**.\n",
        "\n",
        "**Note:** This time we're including the **as_zip = True** feature for downloading.  This skips the unzipping process that typically occurs as part of the downloading function, which some users may prefer to help save disk space."
      ],
      "metadata": {
        "id": "GFi7OycXxlwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_metadata = pd.read_csv('/content/series.csv')\n",
        "\n",
        "uids = series_metadata['Series ID'].tolist()\n",
        "\n",
        "# you'd remove the number parameter if you wanted to download the full dataset\n",
        "nbia.downloadSeries(uids, input_type = 'list', number = 1, as_zip = True)"
      ],
      "metadata": {
        "id": "ArJ3fk6xxmY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inspecting the data more carefully with other tools, you will likely find scans and segmentations that weren't quite what you wanted and that needed to be excluded due to issues like these:\n",
        "\n",
        "1. You might disagree with the way some segmentations were created.\n",
        "2. You may find some segmentations are of organs or something else besides tumors.\n",
        "3. You might find that certain types of CT scans do not work well with your model (e.g. slice thickness is too thick or too thin).\n",
        "4. You might want to exclude some subjects to create a better demographic distribution for gender, race, and ethnicity.\n",
        "\n",
        "After you whittle the dataset down to exactly the CTs and segmentations that you'd like to use to train and test your model you'll need to decide how do you share these with the rest of the world.\n",
        "\n",
        "Our recommendation for the best practice here is to keep track of the Series Instance UIDs!  You can use these in conjunction with the API to create a \"[Shared Cart](https://wiki.cancerimagingarchive.net/display/NBIA/TCIA+Radiology+Portal+User+Guide#TCIARadiologyPortalUserGuide-SharingDatainYourCart)\" that lets you share these specific scans with others.  \n",
        "\n",
        "After creating a Shared Cart you will receive a URL that looks like https://nbia.cancerimagingarchive.net/nbia-search/?saved-cart=nbia-49121659384603347 which can be shared with others.  Try clicking the link to see what this looks like on the TCIA website.  Then use the code below to see how you can achieve this using **tcia_utils**."
      ],
      "metadata": {
        "id": "MEKZlTK0rCe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## makeSharedCart()\n",
        "First let's create a shared cart using **makeSharedCart()**.  This function accepts a list of Series Instance UIDs and (optionally) your cart's name, description and URL (if you want to provide more information about what's in your cart).\n",
        "\n",
        "Let's take a look at how to create one using the **uids** list that we extracted from the **series_metadata** dataframe."
      ],
      "metadata": {
        "id": "fKAid3b5hl0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can update the code below to choose your own custom name if you like.\n",
        "# A random one will generated for you if left empty.\n",
        "name = \"\"\n",
        "description = \"Testing out API cart creation with tcia_utils.\"\n",
        "description_url = \"https://pypi.org/project/tcia-utils/\"\n",
        "\n",
        "carts = nbia.makeSharedCart(uids, name, description, description_url)"
      ],
      "metadata": {
        "id": "Jd7rHRq4ioht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **makeSharedCart()** function returns the URL(s) that can be used to access your shared cart(s).  "
      ],
      "metadata": {
        "id": "hZWoYyI_D2Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "carts"
      ],
      "metadata": {
        "id": "1xn9TUjR3C1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IPI3xhpXggi"
      },
      "source": [
        "## getSharedCart()\n",
        "Users who want to use their browsers can just click on this links and download them using the Data Retriever.  \n",
        "\n",
        "If you want to download the associated series in a cart using the API you can do so by updating the code below to specify the name of the cart you're trying to retrieve. First we'll retrieve the metadata about the cart, and then we can feed that to **downloadSeries()** to actually download the DICOM data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TON4AUIXtO9"
      },
      "outputs": [],
      "source": [
        "df = nbia.getSharedCart(name = \"nbia-58178536016905286-part1\", format = \"df\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbia.downloadSeries(df, input_type = \"df\", number = 1)"
      ],
      "metadata": {
        "id": "cIm06W7MEzoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional TCIA Resources for AI/ML Researchers\n",
        "The following pages on TCIA may be of special interest to deep learning researchers:\n",
        "\n",
        "1. [Finding Annotated Data for AI/ML on TCIA](https://wiki.cancerimagingarchive.net/x/TAGJAw) provides basic guidance for finding datasets that could be useful for deep learning tasks.\n",
        "2. [Challenge Competitions using TCIA data](https://wiki.cancerimagingarchive.net/x/nYIaAQ) can be useful for benchmarking your model's performance.\n",
        "3. [ACR Data Science Institute's Define AI Directory](https://www.acrdsi.org/DSI-Services/Define-AI) links clinically relevant AI use-cases to TCIA datasets that can be used to address them.\n",
        "4. [Additional TCIA Notebooks](https://github.com/kirbyju/TCIA_Notebooks) about accessing and visualizing data are available.\n",
        "\n",
        "# AI/LLM programming tips and tricks for beginners\n",
        "Here are some tips and tricks that can be extremely helpful to novice coders and data scientists thanks to recent advances in AI and LLMs.  We don't have time to dive into them all, but I wanted to provide them to review on your own time.\n",
        "1. Google Colab has built in AI coding assistance.  Try out the auto-complete and `generate with AI` features.  These are excellent tools to speed up your ability to write code within the notebook.\n",
        "2. https://claude.ai/ is an amazing tool for generating code to tackle more in depth tasks.  Rather than helping you write your next line of code, you can write detailed instructions in paragraph form and watch as it generates entire functions or even full scripts/programs for you.  You can then iterate with it via chat to refine specific parts.  You can upload files or larger blobs of code and it seems to generally handle them pretty well in my experience.\n",
        "3. Microsoft Copilot and ChatGPT are also great LLM solutions to help with your code.  For ChatGPT you can even click on \"Explore GPTs\" and try out the ones that are specifically tailored for Python coding.  ChatGPT is also nice in that you can upload full .py files and ask it to analyze them rather than having to copy/paste in code blocks.\n",
        "4. If you find yourself running into message limits when interacting with LLMs, you can alternate back and forth between these different solutions while you wait for your free credits to build back up on the one(s) you've fully depleted.  \n",
        "5. Another option is to install [Ollama](https://ollama.com/download), which lets you run LLMs locally on your laptop with code-specific models like [qwen](https://ollama.com/library/qwen2.5-coder).  The down side here is that the performance may not be quite as good as the commercial solutions, and I've found the user experience to lack behind things like Claude and ChatGPT.\n",
        "\n",
        "Even as someone who is a very novice programmer, these tools have helped me code everything you'll see the rest of this course.  I've also recently discovered [Streamlit](https://streamlit.io/), which makes it super easy to build and deploy small, but very functional, web applications like https://tcia-cohort-builder.streamlit.app/ and https://tcia-shared-cart-creator.streamlit.app/ that interact with our APIs. No sysadmin experience required!  If you come up with an idea for something like this which may benefit other TCIA users, please contact our helpdesk and we'll add it to our list of [Data Analysis Centers](https://wiki.cancerimagingarchive.net/x/x49XAQ)!"
      ],
      "metadata": {
        "id": "rpt0pjo2s_Ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgements\n",
        "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/).  It is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/) and hosted by the [University of Arkansas for Medical Sciences (UAMS)](https://www.uams.edu/).\n",
        "\n",
        "This notebook was created by [Justin Kirby](https://www.linkedin.com/in/justinkirby82/). If you leverage this notebook or any TCIA datasets in your work, please be sure to comply with the [TCIA Data Usage Policy](https://www.cancerimagingarchive.net/data-usage-policies-and-restrictions/). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to the following paper!\n",
        "\n",
        "## TCIA Citation\n",
        "\n",
        "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045–1057. https://doi.org/10.1007/s10278-013-9622-7"
      ],
      "metadata": {
        "id": "LMnX2nBD9cEH"
      }
    }
  ]
}